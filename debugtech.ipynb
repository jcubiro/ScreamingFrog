{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- LIBRARIES IMPORT -- \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# -- INPUTS FOR FUNCTIONS -- \n",
    "\n",
    "## Database Access\n",
    "connector='mysql+pymysql://'\n",
    "user='root:'\n",
    "password='Agramunt54**'\n",
    "ip='@35.234.137.144/'\n",
    "db='Audit'\n",
    "engine='mysql+pymysql://jordi_seo:JrDE3NgZ7fdwfEEr@portals-business-intelligence.cdch0aebdtkv.eu-west-1.rds.amazonaws.com/seo_analysis'\n",
    "\n",
    "## Database Tables and Methods\n",
    "tables=[\"report_test\",\"external_test\",\"inlinks_test\",\"history_test\"]\n",
    "method=['replace','replace','replace','replace','replace','append']\n",
    "\n",
    "## DataFrames for CSV Files\n",
    "PR=pd.read_csv(\"internal_all.csv\")\n",
    "IL=pd.read_csv(\"all_inlinks.csv\")\n",
    "DP=pd.read_csv(\"near_duplicates_report.csv\")\n",
    "EL=pd.read_csv(\"external_links.csv\")\n",
    "SD=pd.read_csv(\"structured_data_all.csv\")\n",
    "\n",
    "## Dataframes List for DB\n",
    "Dataframes=[PR,EL]\n",
    "\n",
    "\n",
    "## Values for Historicals\n",
    "html_to_history=['Backlinks Clusters','Canonicals','Traffic Clusters','Conversion Clusters','Position Clusters','OnPage Titles','OnPage MetaDescriptions','OnPage Word Count']\n",
    "html_suffixes=['_bckl','_cncls','_trfck','_conv','_pos','_tit','_mtde','_wdcnt']\n",
    "site_suffixes=['_arch','_sc']\n",
    "site_to_history=['Archives','Statuses']\n",
    "history=[]\n",
    "\n",
    "## Columns Lists That need to be droped BY DF\n",
    "dropPR=[\"Title 1 Pixel Width\",\"Meta Description 1 Pixel Width\",\"Meta Keyword 1\",\"Meta Keywords 1 Length\",\"H2-1\",\"H2-1 length\",\"H2-2\",\"H2-2 length\",\"URL Encoded Address\",'HTTP rel=\"next\" 1','HTTP rel=\"prev\" 1','% of Total','Hash']\n",
    "dropIL=[\"Size (Bytes)\",\"Alt Text\",\"Type\",\"Status\",\"Status Code\",'Link Path','Path Type','date']\n",
    "to_keep=['Source','Address','Status Code','Alt Text','Anchor','Status Code','Follow','Indexability',\n",
    "'Indexability Status','Link Position','Link Path','Content Type']\n",
    "dropDP=[\"Indexability\",\"Indexability Status\"]\n",
    "\n",
    "\n",
    "\n",
    "## Columns that need to be converted to datetime\n",
    "toTime=[\"GA Avg Session Duration\",\"GA Avg Time on Page\"]\n",
    "\n",
    "# -- FUNCTION CREATION -- \n",
    "\n",
    "def droper(df,toDrop):\n",
    "    try:\n",
    "        for col in toDrop:\n",
    "            if col in df.columns:\n",
    "                del df[col]\n",
    "    except:\n",
    "        print('Could not drop',col)\n",
    "\n",
    "def dater(df):\n",
    "    try:\n",
    "        df['date']=pd.to_datetime('today')\n",
    "        df['date']=df['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    except:\n",
    "        print(\"Heads Error\")\n",
    "        \n",
    "def heads(DataFrames):\n",
    "    try:\n",
    "        for df in DataFrames:\n",
    "            df.columns=df.columns.str.replace(' ','_')\n",
    "            df.columns=df.columns.str.replace('-','_')\n",
    "            df.columns=df.columns.str.lower()\n",
    "    except:\n",
    "        print(\"Heads Error\")\n",
    "\n",
    "        \n",
    "def canonicaliser(df):\n",
    "    if df['Address'] == df['Canonical Link Element 1']:\n",
    "        return 'self canonical'\n",
    "    \n",
    "    elif pd.isnull(df['Canonical Link Element 1']):\n",
    "        return 'missing'\n",
    "    else:\n",
    "        return 'canonicalised'\n",
    "\n",
    "def totime(df,totimes):\n",
    "    try:\n",
    "        for col in totimes:\n",
    "            if col in df.columns:\n",
    "                df[col]=pd.to_datetime(df[col])\n",
    "                df[col]=df[col].dt.strftime('%H:%M:%S')\n",
    "                df[col]=pd.to_timedelta(df[col]).dt.total_seconds().astype(float)\n",
    "                df[col]=df[col].fillna(value=0)\n",
    "    except:\n",
    "        print(\"To Time Error\")\n",
    "\n",
    "def toDB (dataframes,tables,method,engine):\n",
    "    tablenumber=0\n",
    "    n=0\n",
    "    for df in dataframes:\n",
    "        assignedtable=tables[tablenumber]\n",
    "        methodus=method[n] \n",
    "        try:\n",
    "            sqlEngine =create_engine(engine, pool_recycle=3600)\n",
    "            dbConnection=sqlEngine.connect()\n",
    "            frame=df.to_sql(assignedtable, dbConnection, if_exists=methodus, index=False);\n",
    "            tablenumber=tablenumber+1\n",
    "            n=n+1\n",
    "    \n",
    "        except ValueError as vx:\n",
    "            print(vx)\n",
    "    \n",
    "        except Exception as ex:   \n",
    "            print(ex)\n",
    "    \n",
    "        else:\n",
    "            print(\"Table \",assignedtable,\" created successfully.\");   \n",
    "        \n",
    "        finally:\n",
    "            dbConnection.close()\n",
    "\n",
    "\n",
    "def BacklinksClusters(row):\n",
    "    try:\n",
    "        if row['Ahrefs Backlinks - Exact']==0:\n",
    "            val = \"No Backlinks\"\n",
    "\n",
    "        elif row['Ahrefs Backlinks - Exact']>0 and row['Ahrefs Backlinks - Exact']<=10:\n",
    "            val = \"Between 1 and 10 Backlinks\"\n",
    "\n",
    "        elif row['Ahrefs Backlinks - Exact']>10 and row['Ahrefs Backlinks - Exact']<=20:\n",
    "            val = \"Between 11 and 20 Backlinks\"\n",
    "\n",
    "        elif row['Ahrefs Backlinks - Exact']>20 and row['Ahrefs Backlinks - Exact']<=30:\n",
    "            val = \"Between 11 and 20 Backlinks\"\n",
    "\n",
    "        else:\n",
    "            val = \"More than 30 Backlinks\"\n",
    "\n",
    "        return val\n",
    "    except:\n",
    "        print(\"Backlinks Clusters Error\")\n",
    "            \n",
    "\n",
    "def TrafficClusters(row):\n",
    "    try:\n",
    "        if row['GA Users']==0 and row['Status']=='OK':\n",
    "            val= \"URLs with No Users\"\n",
    "        \n",
    "        elif row['GA Users']>0 and row['GA Users']<=10:\n",
    "            val= \"Between 1 and 10 Users\"\n",
    "\n",
    "        elif row['GA Users']>11 and row['GA Users']<=30:\n",
    "            val= \"Between 11 and 30 Users\"\n",
    "\n",
    "        elif row['GA Users']>30 and row['GA Users']<=60:\n",
    "            val= \"Between 31 and 60 Users\"\n",
    "\n",
    "        elif row['GA Users']>60 and row['GA Users']<=100:\n",
    "            val= \"Between 61 and 100 Users\"\n",
    "\n",
    "        elif row['GA Users']>100 and row['GA Users']<=150:\n",
    "            val= \"Between 101 and 150 Users\"\n",
    "\n",
    "        elif row['GA Users']>150 and row['GA Users']<=250:\n",
    "            val= \"Between 151 and 250 Users\"\n",
    "\n",
    "        elif row['GA Users']>250 and row['GA Users']<=350:\n",
    "            val= \"Between 251 and 350 Users\"\n",
    "\n",
    "        elif row['GA Users']>350 and row['Status']=='OK':\n",
    "            val= \"More than 350 Users\"\n",
    "\n",
    "        else: \n",
    "            val=\"URLs with No Users\"\n",
    "        \n",
    "        return val\n",
    "    \n",
    "    except:\n",
    "        print(\"Traffic Clusters Error\")\n",
    "\n",
    "\n",
    "def ConversionClusters(row):\n",
    "    try:\n",
    "        if row['GA Goal 7 Completions']==0 and row['Status']=='OK':\n",
    "            val= \"URLs with No SignUps\"\n",
    "        \n",
    "        elif row['GA Goal 7 Completions']>0 and row['GA Goal 19 Completions']<=10:\n",
    "            val= \"Between 1 and 10 SignUps\"\n",
    "        \n",
    "        elif row['GA Goal 7 Completions']>10 and row['GA Goal 19 Completions']<=20:\n",
    "            val= \"Between 11 and 30 SignUps\"\n",
    "    \n",
    "        elif row['GA Goal 7 Completions']>30 and row['GA Goal 19 Completions']<=50:\n",
    "            val= \"Between 31 and 50 SignUps\"\n",
    "    \n",
    "        elif row['GA Goal 7 Completions']>50 and row['GA Goal 19 Completions']<=100:\n",
    "            val= \"Between 51 and 100 SignUps\"\n",
    "        \n",
    "        elif row['GA Goal 7 Completions']>100:\n",
    "            val= \"More than 100 C2P\"\n",
    "                   \n",
    "        else: \n",
    "            val=\"URLs with No C2Ps\"\n",
    "        \n",
    "        return val\n",
    "    \n",
    "    except:\n",
    "        print('Conversion Cluster Error')\n",
    "\n",
    "def PositionClusters(row):\n",
    "    try:\n",
    "        if row['Position']>0 and row['Position']<=10 and row['Indexability']=='Indexable':\n",
    "            val= \"URLs in TOP 10\"\n",
    "        \n",
    "        elif row['Position']>10 and row['Position']<=20 and row['Indexability']=='Indexable':\n",
    "            val= \"Between 11 and 20 Position\"\n",
    "        \n",
    "        elif row['Position']>20 and row['Position']<=50 and row['Indexability']=='Indexable':\n",
    "            val= \"Between 21 and 50 Position\"\n",
    "    \n",
    "        elif row['Position']>50 and row['Position']<=100 and row['Indexability']=='Indexable':\n",
    "            val= \"Between 50 and 100 Position\"\n",
    "               \n",
    "        else: \n",
    "            val=None\n",
    "        \n",
    "        return val\n",
    "    \n",
    "    except:\n",
    "        print(\"Positions Clusters Error\")\n",
    "\n",
    "def onp_titles(row):\n",
    "    try:\n",
    "        if row['Title 1 Length'] >= 60:\n",
    "            val=\"Title Over 60 Characters\" \n",
    "        elif row['Title 1 Length'] <= 30:\n",
    "            val=\"Title Below 30 Characters\"\n",
    "        else:\n",
    "            val=\"Title Extension OK\"\n",
    "            \n",
    "        return val\n",
    "    except:\n",
    "        print('Onp. Titles Error')\n",
    "\n",
    "def onp_md(row):\n",
    "    try:\n",
    "        if row['Meta Description 1 Length']>160:\n",
    "            val=\"MetaDescription Over 160 Characters\"\n",
    "        \n",
    "        elif row['Meta Description 1 Length']<80:\n",
    "            val=\"MetaDescription Below 80 Characters\"\n",
    "            \n",
    "        else:\n",
    "            val=\"MetaDescription OK\"\n",
    "        return val\n",
    "    except:\n",
    "        print('Onp. Md Error')\n",
    "\n",
    "def onp_word_count(row):\n",
    "    try:\n",
    "        if row['Word Count']>500:\n",
    "            val=\"Content Extension OK\"\n",
    "        \n",
    "        else:\n",
    "            val=\"Low Word Count\"\n",
    "        return val\n",
    "    except:\n",
    "        print('Onp. Word Count Error')\n",
    "\n",
    "def historicalizer(list_of_df,df,column_list,suffixes):  \n",
    "    \"\"\"Passes list of df to history, the dataframe, the column list, and suffixes to use\"\"\"\n",
    "    n=0\n",
    "    try:\n",
    "        for k in column_list:\n",
    "            k=df[k].value_counts().add_suffix(suffixes[n])\n",
    "            k=k.to_frame()\n",
    "            k=k.transpose()\n",
    "            k.reset_index(drop=True, inplace=True)\n",
    "            list_of_df.append(k)\n",
    "            n=n+1\n",
    "    except:\n",
    "        print(\"Historicalizer Error\")\n",
    "        \n",
    "def archive_types(row):\n",
    "    try:\n",
    "        if 'html' in row['Content Type']:\n",
    "            return 'HTML'\n",
    "        \n",
    "        elif 'javascript'in row['Content Type']:\n",
    "            return 'Javascript'\n",
    "    \n",
    "        elif 'image'in row['Content Type']:\n",
    "            return 'Images'\n",
    "        \n",
    "        elif 'css'in row['Content Type']:\n",
    "            return 'css'\n",
    "        \n",
    "        else:\n",
    "            return'other'\n",
    " \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def status_types(row):\n",
    "    if str(row['Status Code']).startswith('2'):\n",
    "        val='2xx'\n",
    "        \n",
    "    elif str(row['Status Code']).startswith('3'):\n",
    "        val='3xx'\n",
    "        \n",
    "    elif str(row['Status Code']).startswith('4'):\n",
    "        val='4xx'\n",
    "        \n",
    "    elif str(row['Status Code']).startswith('5'):\n",
    "        val='5xx'\n",
    "        \n",
    "    else:\n",
    "        val='other'\n",
    "        \n",
    "    return val\n",
    "        \n",
    "# -- DATAFRAME LEVEL MODIFICATIONS --\n",
    "\n",
    "## Drop Columns\n",
    "droper(PR,dropPR)\n",
    "droper(IL,dropIL)\n",
    "droper(DP,dropDP)\n",
    "\n",
    "## ToTime Columns\n",
    "totime(PR,toTime)\n",
    "\n",
    "## Date Assignations\n",
    "dater(PR)\n",
    "dater(DP)\n",
    "\n",
    "\n",
    "# -- SINGLE DF MODIFICATIONS --\n",
    "IL.rename(columns={'Destination':'Address'},inplace=True)\n",
    "LIGHTLINKS=pd.merge(IL,PR,on='Address',how='inner')\n",
    "dropIL=['']\n",
    "[dropIL.append(p) for p in LIGHTLINKS.columns if p not in to_keep]\n",
    "droper(LIGHTLINKS,dropIL)\n",
    "todelete1=LIGHTLINKS[LIGHTLINKS['Content Type']!='text/html; charset=UTF-8'].index \n",
    "LIGHTLINKS=LIGHTLINKS.drop(todelete1)\n",
    "todelete2=LIGHTLINKS[LIGHTLINKS['Source']==LIGHTLINKS['Address']].index\n",
    "LIGHTLINKS=LIGHTLINKS.drop(todelete2)\n",
    "Dataframes.append(LIGHTLINKS)\n",
    "\n",
    "## PR - CLUSTERS\n",
    "PR[\"Canonicals\"]=PR.apply(canonicaliser,axis=1)\n",
    "PR[\"Backlinks Clusters\"]=PR.apply(BacklinksClusters,axis=1)\n",
    "PR[\"Traffic Clusters\"]=PR.apply(TrafficClusters,axis=1)\n",
    "PR[\"Conversion Clusters\"]=PR.apply(ConversionClusters,axis=1)\n",
    "PR[\"Position Clusters\"]=PR.apply(PositionClusters,axis=1)\n",
    "PR[\"OnPage Titles\"]=PR.apply(onp_titles,axis=1)\n",
    "PR[\"OnPage MetaDescriptions\"]=PR.apply(onp_md,axis=1)\n",
    "PR[\"OnPage Word Count\"]=PR.apply(onp_word_count,axis=1)\n",
    "PR[\"Archives\"]=PR.apply(archive_types,axis=1)\n",
    "PR[\"Statuses\"]=PR.apply(status_types,axis=1)\n",
    "\n",
    "## PR Folders Clusterization\n",
    "folders = PR['Address'].str.split(\"/\", expand = True)\n",
    "folders=folders.replace(r'^\\s*$', np.nan, regex=True)\n",
    "folders[3]=folders[3].fillna('Homepage')\n",
    "PR['folder']=folders[3]\n",
    "PR['subfolder']=folders[4]\n",
    "\n",
    "## PR Column Rename\n",
    "PR.rename(columns={'No. Near Duplicates':'num_of_near_duplicates'},inplace=True)\n",
    "pr_html=PR[PR['Content Type']=='text/html; charset=UTF-8']\n",
    "# -- BUILDING HISTORICALS --\n",
    "historicalizer(history,pr_html,html_to_history,html_suffixes)\n",
    "historicalizer(history,PR,site_to_history,site_suffixes)\n",
    "historicals=pd.concat(history,axis=1) \n",
    "historicals['URLs Crawled']=len(PR.index)\n",
    "historicals['duplicates_amount']=pr_html['num_of_near_duplicates'].sum()\n",
    "historicals.columns=historicals.columns.astype(str)\n",
    "dater(historicals)\n",
    "Dataframes.append(historicals)\n",
    "\n",
    "\n",
    "# -- STRINGS FORMATTING --\n",
    "heads(Dataframes)\n",
    "\n",
    "\n",
    "# -- DATABASE UPLOAD --\n",
    "\n",
    "toDB(Dataframes,tables,method,engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
